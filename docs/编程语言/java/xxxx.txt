1.什么是分布式锁？
    分布式锁，即分布式系统中的锁。在单体应用中我们通过锁解决的是控制共享资源访问的问题，而分布式锁，就是解决了分布式系统中控制共享资源访问的问题。与单体应用不同的是，分布式系统中竞争共享资源的最小粒度从线程升级成了进程。
2.分布式锁应该具备哪些条件：
     在分布式系统环境下，一个方法在同一时间只能被一个机器的一个线程执行
     高可用的获取锁与释放锁
     高性能的获取锁与释放锁
     具备可重入特性（可理解为重新进入，由多于一个任务并发使用，而不必担心数据错误）
     具备锁失效机制，即自动解锁，防止死锁
     具备非阻塞锁特性，即没有获取到锁将直接返回获取锁失败
3.分布式锁应用场景有哪些？
    1，处理效率提升：引用分布式锁，可以减少重复任务的执行，避免资源处理效率的浪费；
    2，数据准确性保障：使用分布式锁可以放在数据资源的并发访问，避免数据不一致情况，甚至数据损失等 。
4、hashCode()与 equals()之间的关系
    在 Java 中，每个对象都可以调⽤⾃⼰的 hashCode()⽅法得到⾃⼰的哈希值(hashCode)，相当于对象的指纹信息，通常来说世界上没有完全相同的两个指纹，但是在 Java 中做不到这么绝对，但是我们仍然可以利⽤hashCode 来做⼀些提前的判断，⽐如：
    如果两个对象的 hashCode 不相同，那么这两个对象肯定不同的两个对象
    如果两个对象的 hashCode 相同，不代表这两个对象⼀定是同⼀个对象，也可能是两个对象
    如果两个对象相等，那么他们的 hashCode 就⼀定相同
5、泛型中 extends 和 super 的区别
    <? extends T>表示包括 T 在内的任何 T 的⼦类
    <? super T>表示包括 T 在内的任何 T 的⽗类
6、重载和重写的区别
    1、重载实现的是编译时的多态性，而重写实现的是运行时的多态性。
    2、重载发生在一个类中，同名的方法的参数列表要不同；而重写发生在子类与父类之间，重写方法的重写方法要相同。
    3、重载方法的返回类型可以修改，而重写方法不能。
    4、重载方法的异常可以修改，重写方法的异常可以减少或删除，一定不能抛出新的或者更广的异常。
    5、重载方法的访问可以修改，而重写方法的访问一定不能做更严格的限制。
18、Java 中有哪些类加载器
    引导类加载器（Bootstrap Class Loader）：
    引导类加载器是最顶层的类加载器，它负责加载 Java 平台核心类库（如 rt.jar）以及其他被虚拟机认可的基础类库。它是用本地代码实现的，不继承自 java.lang.ClassLoader，因此在 Java 程序中无法直接获取到引导类加载器的引用。
    扩展类加载器（Extension Class Loader）：
    扩展类加载器是用于加载 Java 平台的扩展库（如 jre/lib/ext 目录下的 JAR 文件）。它是由 sun.misc.Launcher$ExtClassLoader 实现的，并由 Java 核心类库提供。
    应用程序类加载器（Application Class Loader）：
    应用程序类加载器是 Java 程序中默认的类加载器，也是大多数开发者最常接触到的类加载器。它负责加载应用程序的类路径（Classpath）上指定的类库和用户自定义类。应用程序类加载器是由 sun.misc.Launcher$AppClassLoader 实现的，并由 Java 核心类库提供。
    除了这三种常见的类加载器之外，还有一些特殊的类加载器，如：
    自定义类加载器：
    Java 提供了一系列用于自定义类加载器的 API，开发者可以通过继承 java.lang.ClassLoader 类来实现自定义的类加载器。自定义类加载器通常用于特定的需求，比如从非标准的位置加载类、对类进行特殊的处理等。
    平台类加载器（Platform Class Loader）：
    平台类加载器是在 Java 9 中引入的新的类加载器。它是扩展类加载器的子类，负责加载 JDK 内部模块的类。
19、说说类加载器双亲委派模型
    当一个类加载器需要加载某个类时，它首先将加载请求委托给父类加载器。
    父类加载器也会按照同样的方式将加载请求向上委托给它的父类加载器，直至请求到达顶层的引导类加载器。
    如果顶层的引导类加载器无法加载该类，那么将会回溯，子类加载器尝试自己加载该类。
    如果子类加载器仍然无法找到所需的类，它会反馈给父类加载器，父类加载器会尝试自己加载该类。
    如果所有的父类加载器都无法加载该类，最终由子类加载器自己尝试加载该类
24、JVM 有哪些垃圾回收算法?
    标记-清除算法（Mark and Sweep）：
    标记-清除算法是最基础的垃圾回收算法之一。它通过两个阶段进行：首先标记出所有活动对象，然后清除未标记的对象。该算法的缺点是会产生大量的碎片空间，影响内存的连续分配。
    复制算法（Copying）：
    复制算法将可用内存划分为两个相等大小的区域，每次只使用其中的一个区域。当当前区域的内存空间用尽时，将活动对象复制到另一个区域，并清除已使用的内存。该算法解决了碎片问题，但是浪费了一半的内存空间。
    标记-压缩算法（Mark and Compact）：
    标记-压缩算法首先标记出所有活动对象，然后将它们压缩到内存的一端，清理掉压缩后的空间。该算法既解决了碎片问题，又减少了内存的浪费，但是需要移动对象，可能会造成一定的性能开销。
    分代算法（Generational）：
    分代算法基于对象的生命周期将内存划分为不同的代（Generation），一般分为年轻代（Young Generation）、老年代（Old Generation）和持久代（Permanent Generation/Metaspace）。年轻代中的对象生命周期较短，采用复制算法，老年代中的对象生命周期较长，采用标记-压缩算法。分代算法利用了不同代的特点，根据对象的特征进行不同的垃圾回收策略，提高了垃圾回收的效率。
    并发标记-清除算法（Concurrent Mark and Sweep）：
    并发标记-清除算法是一种并发垃圾回收算法，它在垃圾回收过程中允许应用程序继续执行。该算法通过并发标记活动对象，并在标记完成后，暂停应用程序线程来执行清除操作。这样可以减少停顿时间，但可能会增加算法的复杂性和开销。
31、Java 死锁如何避免?
    避免循环等待：在设计多线程程序时，尽量避免线程之间形成循环等待资源的关系。可以通过对资源进行排序，按照一定的顺序申请资源，从而避免循环等待的情况发生。
    使用资源分级：将资源进行分级，每个线程按照固定的顺序获取资源，释放资源时按相反的顺序释放。这种方式可以避免多个线程同时获取多个资源的顺序不一致导致死锁的问题。
    加锁顺序：规定所有的线程必须按照相同的顺序获取锁。如果多个线程需要获取多个锁，确保它们以相同的顺序获取锁，可以减少死锁的发生。
    使用超时机制：在获取锁时设置一个超时时间，如果在规定时间内没有获取到锁，就放弃或尝试其他操作。这样可以避免线程长时间等待锁而导致的死锁。
    使用资源分配策略：采用合适的资源分配策略，避免出现资源不足的情况。例如，采用动态分配资源的方法，根据实际需求分配资源，可以减少死锁的概率。
    死锁检测与恢复：通过定期检测系统中的死锁情况，并采取相应的措施进行恢复。可以使用算法来检测死锁，一旦检测到死锁，可以通过资源回收或线程终止来解决死锁问题。
32、线程池的底层工作原理
    线程池是一种常见的并发编程模型，它允许我们有效地管理和复用线程来执行任务。线程池的底层工作原理可以总结如下：
    线程池初始化：在创建线程池时，我们需要指定线程池的大小，即同时可以执行的线程数量。线程池通常会预先创建一定数量的线程，这些线程会一直存在并等待任务的到来。
    任务队列：线程池内部维护一个任务队列，用于存储需要执行的任务。当有新的任务提交给线程池时，线程池会将任务添加到任务队列中。
    任务调度：线程池中的线程会不断从任务队列中获取任务进行执行。线程池的调度算法可以根据不同的策略进行选择，例如先进先出(FIFO)、优先级等。
    线程复用：当一个线程完成了任务的执行后，并不会立即销毁，而是返回线程池并等待下一个任务的到来。这样可以避免频繁地创建和销毁线程，提高线程的复用性和效率。
    线程管理：线程池还负责管理线程的状态和生命周期。线程池可以监控线程的运行状态，当线程出现异常或长时间未响应时，线程池可以将其标记为无效，并创建新的线程来替代。
34、ReentrantLock 中的公平锁和非公平锁的底层实现
    公平锁（Fair Lock）：
    公平锁是按照线程请求锁的顺序来获取锁的，即先到先得。
    在公平锁中，锁的获取和释放是基于AQS（AbstractQueuedSynchronizer）的FIFO队列。当一个线程请求公平锁时，如果发现锁已被其他线程持有，该线程会被加入到等待队列中，按照先到先得的顺序等待锁的释放。
    公平锁的优点是保证了线程获取锁的公平性，避免了线程饥饿现象。但是由于需要维护一个等待队列，并进行频繁的线程切换，可能会带来一定的性能开销。
    非公平锁（Nonfair Lock）：
    非公平锁允许线程插队获取锁，即如果锁当前是可用的，一个线程可以直接获取锁，而不用管其他线程是否在等待锁。
    在非公平锁中，当一个线程请求锁时，会先尝试直接获取锁，如果获取失败才会将线程加入等待队列。
    非公平锁的优点是相对于公平锁，减少了线程切换的次数，提高了系统的吞吐量。但是由于线程可能插队获取锁，导致某些线程可能一直无法获取到锁，产生饥饿现象。
    在ReentrantLock中，默认情况下是非公平锁，即构造函数未指定fair参数时为非公平锁。可以通过在构造ReentrantLock对象时显式传入true来创建公平锁，传入false或不指定则创建非公平锁。
38、Sychronized 和 ReentrantLock 的区别
    可重入性：
    Synchronized是Java内置的关键字，具有隐式的可重入性。当一个线程持有了某个对象的锁，它可以重复地进入由该对象的同步代码块或同步方法组成的区域，而不会被阻塞。
    ReentrantLock是Java中的一个类，也支持可重入性。当一个线程持有了ReentrantLock锁，它可以多次获取该锁，每次获取都会增加锁的计数，需要释放相同次数的锁才能完全释放。
    锁的获取方式：
    Synchronized是隐式锁，它的获取和释放由Java虚拟机自动管理。当线程进入Synchronized块或方法时，它会自动获取锁；当线程退出Synchronized块或方法时，它会自动释放锁。
    ReentrantLock是显式锁，它需要手动进行获取和释放。通过调用lock()方法获取锁，通过调用unlock()方法释放锁。由于需要手动管理锁的获取和释放，因此需要特别注意在使用ReentrantLock时避免忘记释放锁，可能会导致死锁的问题。
    锁的灵活性：
    Synchronized是非公平锁，它不保证线程获取锁的顺序。当多个线程同时请求锁时，某个线程获取到锁的概率较大，但不能保证先到先得。
    ReentrantLock可以作为公平锁或非公平锁来使用。通过在构造ReentrantLock对象时指定公平性，可以决定线程获取锁的顺序。公平锁会按照线程请求锁的顺序进行获取，而非公平锁则允许某个线程插队获取锁。
    功能扩展：
    ReentrantLock相比Synchronized提供了更多的高级功能，如可中断锁、超时锁等。ReentrantLock还支持Condition条件，可以方便地实现等待/通知机制。
    综上所述，Synchronized是Java内置的关键字，使用简单但功能相对较少；而ReentrantLock是一个类，提供了更多的高级功能和灵活性，但使用相对复杂。在选择使用哪种机制时，可以根据具体的需求和场景来进行选择。一般来说，对于简单的同步需求，Synchronized已经足够；而对于复杂的同步需求或需要更多灵活性的情况，可以选择使用ReentrantLock。
39、谈谈你对 AQS 的理解，AQS 如何实现可重入锁?
    AQS（AbstractQueuedSynchronizer）是Java并发包中的一个抽象类，它提供了一种用于构建同步器的框架。AQS以队列的形式管理多个线程的竞争和等待，并通过子类的实现来定义同步状态的获取和释放。
    AQS实现可重入锁（Reentrant Lock）的基本思想是，使用一个整数表示锁的状态，当状态为0时表示锁是空闲的，大于0时表示锁被某个线程占用。具体来说，AQS维护了一个同步状态（state）和一个等待队列（wait queue）。当一个线程请求获取锁时，AQS会根据当前状态判断是否能够获得锁，如果能够获得锁，则将状态设置为一个正数，并将锁的拥有者设为当前线程；如果不能获得锁，则将当前线程加入等待队列中。
    AQS实现可重入锁的关键在于对同一个线程的重入支持。每个线程在持有锁时，AQS会记录持有线程的标识和持有次数。当同一个线程再次请求获取锁时，AQS会检查当前线程是否已经持有锁，如果是，则直接增加持有次数，并且不会阻塞当前线程；如果不是，则按照正常的加锁流程处理。
    AQS使用了模板方法模式，通过子类的实现来定义具体的同步语义。子类需要实现AQS的几个核心方法，包括获取锁（tryAcquire）、释放锁（tryRelease）以及判断是否有其他线程需要阻塞（hasQueuedPredecessors）等。在实现可重入锁时，子类需要覆写tryAcquire和tryRelease方法，确保对同一个线程的重入操作能够正确处理。
    总结来说，AQS通过维护同步状态和等待队列的方式实现了可重入锁。它的设计提供了一种通用的同步器框架，可以方便地构建不同类型的同步器，如独占锁、共享锁等，并且支持可重入性、公平性等高级特性。
40、谈谈你对 IoC 的理解
    IoC（Inversion of Control，控制反转）是一种软件设计原则和编程模式，它的核心思想是将对象的创建和依赖关系的管理交由容器来负责，而不是由应用程序显式地创建和管理对象。
    在传统的编程模式中，应用程序通常会直接创建和管理对象，对象之间的依赖关系也由应用程序自己来维护。这样做会导致应用程序高度耦合，难以扩展和测试，并且增加了代码的复杂性。
    而IoC通过将对象的创建和依赖关系的管理转移到容器中，实现了应用程序与对象之间的解耦。在IoC的模式下，应用程序只需要声明需要哪些对象以及它们之间的关系，而不需要关心对象是如何创建和管理的。容器负责根据配置信息创建对象，并自动解析和注入对象之间的依赖关系。
    IoC的主要优点包括：
    降低代码耦合：应用程序只需要关注业务逻辑，不需要关心对象的创建和依赖关系。
    提高可扩展性：通过配置文件或注解来管理对象的创建和依赖关系，可以方便地对应用程序进行扩展和修改。
    便于测试：可以通过容器来创建和管理对象，方便进行单元测试和模拟对象。
    提高代码的可读性和可维护性：将对象的创建和依赖关系集中管理，代码更加清晰简洁。
    在Java开发中，Spring框架是一个广泛使用IoC的框架。它通过依赖注入（Dependency Injection，DI）来实现IoC，通过XML配置文件、注解或Java配置类来描述对象的创建和依赖关系，由Spring容器负责创建对象并注入依赖。这样可以使得Java开发更加灵活、可扩展和易于维护。
42、Spring 事务传播机制
    REQUIRED（默认）：如果当前存在事务，则加入当前事务，如果没有事务，则创建一个新的事务。在REQUIRED传播行为下，多个方法共享同一个事务，如果其中一个方法出现异常并回滚，整个事务都将回滚。
    SUPPORTS：如果当前存在事务，则加入当前事务，如果没有事务，则以非事务的方式执行。在SUPPORTS传播行为下，方法可以选择加入当前事务或以非事务的方式执行，如果没有事务，方法会以非事务的方式执行。
    MANDATORY：必须存在一个当前的事务，如果没有事务，则抛出异常。MANDATORY传播行为要求方法必须在一个事务中执行，如果没有事务，则会抛出异常。
    REQUIRES_NEW：每次都创建一个新的事务，如果当前存在事务，则挂起当前事务。在REQUIRES_NEW传播行为下，每次方法都会创建一个新的事务，当前事务会被挂起，直到方法执行完成。
    NOT_SUPPORTED：以非事务的方式执行方法，如果当前存在事务，则挂起当前事务。在NOT_SUPPORTED传播行为下，方法以非事务的方式执行，当前事务会被挂起。
    NEVER：以非事务的方式执行方法，如果当前存在事务，则抛出异常。NEVER传播行为要求方法在非事务的环境中执行，如果当前存在事务，则会抛出异常。
    NESTED：如果当前存在事务，则在嵌套事务中执行，如果没有事务，则创建一个新的事务。在NESTED传播行为下，方法在一个嵌套的事务中执行，嵌套事务是外部事务的一部分，如果嵌套事务回滚，则只回滚嵌套事务，而不会回滚外部事务。
43、Spring 事务什么时候会失效?
    不受事务管理的方法：如果在一个没有受到事务管理的方法中调用了一个带有事务注解的方法，那么事务将不会生效。这是因为Spring的事务管理是基于代理的，只有通过代理调用的方法才能被事务管理器拦截。
    异常的捕获和处理：当方法中的异常被捕获并在方法内部进行处理时，Spring事务可能会失效。如果异常被捕获并在方法内部进行处理，事务管理器无法感知到异常的存在，因此无法触发回滚操作。
    事务传播行为设置不当：在使用声明式事务时，如果事务的传播行为设置不当，也可能导致事务失效。例如，如果在一个已经存在事务的上下文中执行一个不受事务管理的方法，那么事务将被挂起，事务管理将失效。
    未受支持的异常：默认情况下，Spring只会对RuntimeException及其子类进行事务回滚。如果方法抛出的异常不是RuntimeException或其子类，事务管理器将不会触发回滚操作，导致事务失效。
    事务的隔离级别设置不当：如果在事务中设置了较低的隔离级别，可能会导致并发冲突和数据不一致的情况，从而使事务失效。
    数据库引擎不支持事务：如果所使用的数据库引擎不支持事务，或者事务功能被禁用，那么Spring的事务管理将无法生效。
44、Spring 中的 Bean 创建的生命周期有哪些步骤
    实例化（Instantiation）：容器根据Bean的定义，通过反射或其他方式创建Bean的实例。
    属性填充（Population）：容器将Bean的属性值（通过构造函数、setter方法或注解）注入到Bean实例中。
    初始化前回调（Initialization Callback）：在Bean实例创建完成后，可以通过实现InitializingBean接口或在配置文件中配置init-method来定义初始化前的回调方法。
    初始化（Initialization）：容器对Bean进行一些初始化的操作，如执行自定义的初始化逻辑、连接数据库、建立网络连接等。
    初始化后回调（Post-Initialization Callback）：在Bean初始化完成后，可以通过实现BeanPostProcessor接口来定义初始化后的回调方法，对Bean进行额外的处理。
    使用（In Use）：Bean可以被应用程序使用，调用其方法和访问其属性。
    销毁前回调（Destruction Callback）：在容器关闭或销毁Bean之前，可以通过实现DisposableBean接口或在配置文件中配置destroy-method来定义销毁前的回调方法。
    销毁（Destruction）：容器对Bean进行一些销毁的操作，如关闭数据库连接、释放资源等。
45、Spring 中 Bean 是线程安全的吗
    在Spring中，Bean的线程安全性取决于具体的Bean实现和配置。Spring容器本身并不能保证所有的Bean都是线程安全的，而是提供了一些机制和选项来支持线程安全的Bean实现。
    单例模式：默认情况下，Spring容器中的Bean是以单例模式创建和管理的。在单例模式下，多个线程共享同一个Bean实例，因此需要确保Bean的线程安全性。开发者需要自行保证在多线程环境下访问Bean时的线程安全性。
    原型模式：如果将Bean的作用域设置为原型（prototype），则每次从容器中获取Bean时都会创建一个新的实例。在原型模式下，每个线程都拥有独立的Bean实例，不会出现线程安全问题。
    同步控制：开发者可以在Bean的实现中使用同步控制机制（如synchronized关键字、Lock对象等）来确保线程安全性。通过适当地使用同步机制，可以在多线程环境下保护共享资源的访问。
    避免共享状态：一个常见的做法是避免在Bean中使用共享的状态，尽量将Bean设计为无状态的或者使用线程本地变量来存储线程相关的状态。这样可以避免多线程访问共享状态的竞争和冲突。
46、ApplicationContext 和 BeanFactory 有什么区别
    功能范围：ApplicationContext是BeanFactory的子接口，提供了更多的功能和特性。ApplicationContext不仅能够管理Bean的生命周期和依赖关系，还提供了国际化、事件发布、资源管理等高级特性。而BeanFactory提供了基本的Bean管理功能，包括实例化Bean、属性注入和依赖解析等。
    预加载：ApplicationContext在启动时会预加载所有的单例Bean，即在容器初始化时就实例化并初始化所有的单例Bean对象。而BeanFactory则是按需加载，只有在获取Bean时才进行实例化和初始化。
    资源访问：ApplicationContext能够访问更多的资源，包括文件系统、类路径、URL等。它提供了更多的资源加载和管理的方法，例如获取资源文件、发布和监听事件等。而BeanFactory则主要关注于Bean的管理和依赖注入，不涉及资源访问。
    扩展性：由于ApplicationContext提供了更多的功能和特性，它更易于扩展和定制。例如，可以通过编写自定义的ApplicationContext实现类来扩展容器的行为。而BeanFactory的功能相对较少，扩展性较弱。
48、Spring 中什么时候 @Transactional 会失效
    注解未被扫描到：如果@Transactional注解所在的类或方法没有被Spring容器扫描到，那么注解将不会生效。请确保类或方法被正确地配置为Spring的Bean，并被容器扫描到。
    异常未被捕获：默认情况下，Spring只会对未被捕获的RuntimeException及其子类进行事务回滚。如果在事务方法中捕获了异常，并在catch块中进行了处理，事务将不会回滚。要使@Transactional注解生效，确保异常未被捕获或重新抛出
    方法调用不通过代理对象：Spring的事务管理是通过AOP代理来实现的。当通过this关键字直接调用方法时，事务注解将不会生效。因为this关键字是指向当前对象的引用，而不是代理对象。要使@Transactional注解生效，通过代理对象调用方法。
    同一个类内部的自调用：当在同一个类内部的方法之间进行调用时，事务注解将不会生效。因为Spring的事务管理是基于AOP代理实现的，自调用方法会绕过代理，事务注解将不起作用。
    异步方法：使用Spring的@Async注解标记的方法是异步执行的，事务注解在异步方法上可能不会生效。如果需要在异步方法中使用事务，请参考Spring的异步事务处理方式。
49、Spring 容器启动流程是怎样的
    加载配置文件：Spring容器会读取并解析配置文件，常见的配置文件包括XML配置文件（如applicationContext.xml）或基于注解的配置类。
    创建Bean定义：在加载配置文件后，Spring容器会根据配置信息创建相应的Bean定义。Bean定义包含了Bean的类型、依赖关系、作用域等元数据。
    实例化Bean：根据Bean定义，Spring容器会实例化相应的Bean对象。实例化过程中，可以执行构造函数注入或静态工厂方法等方式来创建Bean实例。
    设置Bean属性：一旦Bean实例化完成，Spring容器会根据配置信息或注解设置Bean的属性值，可以通过setter方法注入或字段注入等方式。
    处理Bean依赖：如果Bean之间存在依赖关系，Spring容器会解析和处理这些依赖关系。可以通过构造函数注入、setter方法注入或基于注解的依赖注入来满足Bean之间的依赖关系。
    初始化Bean：初始化过程中，Spring容器会调用Bean的初始化方法，可以通过实现InitializingBean接口或使用@PostConstruct注解来定义初始化方法。
    注册Bean：在Bean初始化完成后，Spring容器会将Bean注册到容器中，以便在其他地方可以通过名称或类型进行查找和获取。
    完成启动：完成Bean的注册后，Spring容器启动完成，可以使用已经初始化和注册的Bean进行业务操作。
52、Spring Boot 是如何启动 Tomcat 的
    引入Tomcat依赖：在项目的pom.xml文件中，通过Spring Boot的依赖管理工具引入Tomcat的依赖。可以使用spring-boot-starter-web依赖来引入Tomcat和其他相关的Web组件。
    创建Spring Boot应用类：在应用的主类中，使用@SpringBootApplication注解标记该类作为Spring Boot应用的入口点。该注解会自动进行一些配置，包括自动扫描和加载组件等。
    启动Tomcat容器：在主类的main方法中，使用SpringApplication.run()方法来启动Spring Boot应用。该方法会自动启动嵌入式的Tomcat容器，并加载并初始化应用程序。
    配置Tomcat属性：可以通过在application.properties或application.yml文件中配置Tomcat的属性。例如，可以配置端口号、上下文路径、连接池等相关属性。
    部署和运行Web应用程序：在Spring Boot应用启动后，Tomcat会自动加载应用程序的Servlet和其他Web组件，并根据配置的URL映射来处理HTTP请求。
53、Mybatis 的优缺点
    简单易用：MyBatis相对于其他ORM框架来说，学习和使用成本相对较低。它使用简单的XML或注解配置来映射Java对象和SQL语句，使得开发人员可以更容易地编写和维护数据库访问代码。
    灵活性高：MyBatis提供了灵活的SQL编写方式，可以直接编写SQL语句，对于复杂的查询和数据操作，开发人员可以更好地控制和优化SQL语句，以满足特定的需求。
    性能优化：MyBatis支持一级缓存和二级缓存机制，可以减少数据库的访问次数，提高系统的性能。此外，MyBatis还支持延迟加载，可以在需要时才加载关联的数据，减少不必要的查询。
    易于集成：MyBatis可以与各种主流的Java框架和持久层工具进行集成，如Spring框架、Spring Boot等，使得开发人员可以方便地将MyBatis与其他组件结合使用。
    缺点：
    开发量大：相比于全自动的ORM框架，使用MyBatis需要手动编写SQL语句，需要开发人员具备一定的SQL知识和技能。对于简单的增删改查操作，使用MyBatis可能需要编写更多的代码。
    与数据库的耦合度高：MyBatis需要开发人员手动编写SQL语句，这意味着SQL语句与具体的数据库厂商相关，可能需要根据不同的数据库进行调整和优化，增加了与数据库的耦合度。
    易错性高：由于MyBatis是基于手写SQL语句的，开发人员需要自行保证SQL语句的正确性和安全性，容易出现拼写错误、SQL注入等问题。
56、索引设计的原则?
    选择合适的索引列：选择频繁用于查询条件的列作为索引列，例如经常用于过滤、排序或连接的列。索引列应该是具有高选择性的，即它们的值具有较高的唯一性，可以过滤出较少的数据行。
    考虑索引的复合列：如果多个列经常一起使用作为查询条件，可以创建复合索引，以包含这些列。复合索引可以提高查询的效率，减少索引的数量和占用空间。
    避免过多的索引：过多的索引会增加数据库的维护成本和额外的存储空间。只创建必要的索引，避免对不常使用的列创建索引。
    考虑查询的顺序：索引的顺序可以影响查询的效率。如果查询中的排序和分组操作是常见的，可以考虑将这些列包含在索引中，以避免额外的排序操作。
    注意索引的大小：索引会占用额外的存储空间，因此需要注意索引的大小。对于大型表和频繁更新的表，需要仔细评估索引的大小和性能开销。
    定期维护和优化索引：索引的性能可以随着数据的变化而变化，需要定期进行索引维护和优化，例如重新组织索引、删除不必要的索引等。
    监测和分析索引的使用情况：监测和分析索引的使用情况可以帮助判断索引的效果和性能。数据库系统提供了相关的监控和性能分析工具，可以用于评估索引的使用情况和效果。
57、事务的基本特性和隔离级别
    原子性（Atomicity）：事务是一个不可分割的工作单位，要么全部执行成功，要么全部回滚到初始状态。事务的所有操作要么全部提交，要么全部撤销。
    一致性（Consistency）：事务执行前后，数据库的状态必须保持一致。事务的执行不能破坏数据库的完整性约束，例如唯一性约束、外键约束等。
    隔离性（Isolation）：并发执行的事务之间应该相互隔离，每个事务的执行应该像是在独立的环境中进行的，即使并发执行，也不会互相干扰。隔离性可以防止并发执行时出现的一些问题，如脏读、不可重复读和幻读。
    持久性（Durability）：一旦事务提交，其所做的修改将会永久保存在数据库中，即使发生系统故障或重启，修改的数据也不会丢失。
    隔离级别定义了不同事务之间的隔离程度，常见的隔离级别有四个：
    读未提交（Read Uncommitted）：最低的隔离级别，事务可以读取其他事务未提交的数据。可能出现脏读、不可重复读和幻读的问题。
    读提交（Read Committed）：保证事务只能读取到已提交的数据，禁止脏读。但可能出现不可重复读和幻读的问题。
    可重复读（Repeatable Read）：在事务执行期间，多次读取同一数据将会得到一致的结果，不会出现不可重复读的问题。但仍可能出现幻读的问题。
    串行化（Serializable）：最高的隔离级别，事务串行执行，保证了最高的隔离性。可以避免脏读、不可重复读和幻读的问题，但性能较低。
64、B 树和 B+树的区别，为什么 Mysq|使用 B+树
    存储方式：B树的每个节点既包含键值，也包含对应的数据，而B+树的内部节点只包含键值，所有的数据都存储在叶子节点上。叶子节点通过链表连接在一起。
    节点结构：B树的节点包含键值和对应数据的指针，这使得B树的节点更大。相比之下，B+树的节点只包含键值，因此B+树的节点更小，一个节点可以存储更多的键值。
    查询方式：在B树中，通过内部节点进行查找，可以直接定位到对应的数据。而在B+树中，只有叶子节点包含数据，所有的查询操作都是从根节点到叶子节点的搜索过程。
65、Mysql 锁有哪些，如何理解
    行级锁（Row-level Locks）：行级锁是MySQL中最细粒度的锁，它在操作数据行时对该行进行加锁。行级锁可以防止并发事务之间的读写冲突，提供了较高的并发性。MySQL的InnoDB存储引擎默认使用行级锁。
    表级锁（Table-level Locks）：表级锁是在整个表上加锁，可以用于控制对整个表的并发访问。表级锁分为共享锁和排他锁。共享锁（S锁）允许多个事务同时获取读锁，但阻止其他事务获取写锁。排他锁（X锁）则只允许一个事务获取写锁，并阻止其他事务获取读锁和写锁。表级锁的粒度较粗，会限制并发性能。
    页级锁（Page-level Locks）：页级锁是在数据页（通常是16KB大小）上加锁，它介于行级锁和表级锁之间。页级锁的粒度较大，可以减少锁的开销，但在高并发情况下可能会引起锁竞争。
66、Mysq|懂查询该如何优化?
    使用适当的索引：通过创建合适的索引可以加快查询速度。根据查询条件和表结构，选择合适的列作为索引，并确保索引的选择性高。
    优化查询语句：使用合适的查询语句可以减少数据库的负载。避免使用SELECT * 查询所有列，只查询需要的列。同时，优化复杂的查询语句，避免多次嵌套子查询和不必要的连接操作。
    避免全表扫描：尽量避免在大表中进行全表扫描，因为它会消耗大量的资源。使用索引或者优化查询语句来尽量减少全表扫描的情况。
    避免使用OR条件：在查询语句中使用OR条件会导致MySQL无法使用索引，影响查询性能。尽量使用AND条件或者使用UNION操作来替代OR条件。
    分页查询优化：对于大数据量的分页查询，使用LIMIT和OFFSET来限制返回的记录数，避免查询整个结果集。
    使用连接池：通过使用连接池可以减少数据库连接的开销，提高查询性能。连接池可以维护一组预先建立的数据库连接，重复利用已经建立的连接，避免频繁地创建和关闭连接。
    数据库缓存优化：合理设置数据库缓存参数，如查询缓存和InnoDB缓冲池大小，以减少磁盘I/O操作，提高查询速度。
    数据库表设计优化：合理设计数据库表的结构和关系，避免过度规范化或冗余字段。优化表的主键、外键和索引的设计，以提高查询性能。
    数据库服务器优化：优化数据库服务器的硬件和配置，如增加内存、调整磁盘参数、优化数据库参数配置等，以提高整体的查询性能。
68、Redis 的过期键的删除策略
    定期删除：Redis每隔一段时间（默认是100毫秒）会随机抽取一部分设置了过期时间的键进行检查，删除其中已过期的键。这个操作通过redisServer结构中的hz属性来控制执行的频率。
    惰性删除：当访问某个键时，Redis会先检查该键是否过期，如果过期则删除。这种删除方式是惰性的，即在访问时才进行删除操作，而不是事先批量删除过期键。这样可以减少内存的使用，避免在没有必要的情况下进行键的删除操作。
69、简述 Redis 事务实现
    Redis事务是一组命令的原子操作序列，它们被当作一个单独的操作来执行，要么全部执行成功，要么全部回滚。Redis事务通过MULTI、EXEC、WATCH和DISCARD等命令来实现。
    Redis事务的实现过程如下：
    MULTI命令：事务开始时，通过执行MULTI命令进入事务状态。此后，所有的命令都不会立即执行，而是进入队列等待。
    执行事务命令：在事务状态下，可以依次执行多个命令，这些命令都会被加入到事务队列中。
    EXEC命令：当执行EXEC命令时，Redis会按照先进先出的顺序，依次执行事务队列中的命令。如果中途出现错误，执行会终止，并返回错误信息。如果全部执行成功，返回每个命令的执行结果。
    WATCH命令：WATCH命令用于对一个或多个键进行监视。如果在EXEC执行前，被监视的键发生了修改，整个事务会被放弃，不执行任何命令。
    DISCARD命令：DISCARD命令用于取消当前事务，并清空事务队列中的所有命令。
70、Redis 主从复制的核心原理
    同步：主节点将数据同步到从节点。主节点将写操作记录在内存中的命令序列（AOF日志或RDB文件），然后将这些命令发送给所有连接的从节点。从节点接收到命令后，执行相同的写操作来保持数据的一致性。在初始同步过程中，从节点会执行全量复制，即复制主节点上的所有数据。之后的增量同步中，主节点会将写操作实时地传播给从节点。
    心跳检测：主节点和从节点之间通过心跳检测来保持连接的活跃性。主节点会定期发送心跳包给从节点，从节点则会响应心跳包来表明其正常运行。如果主节点长时间未收到从节点的响应，则会判断从节点宕机或网络故障，并将其标记为不可用。
    故障恢复：当主节点宕机或不可用时，系统需要进行故障恢复。Redis采用自动故障转移的方式来实现主节点的自动切换。当主节点不可用时，Redis集群中的哨兵节点会选举出一个新的主节点，并将其他节点切换为从节点。此时，集群将会重新进行数据同步，将新的写操作传播给从节点。
71、Redis 有哪些数据结构?分别有哪些典型的应用场景?
    字符串（String）：字符串是Redis最基本的数据结构，用于存储字符串值。字符串可以存储任意类型的数据，例如缓存数据、计数器、分布式锁等。
    哈希（Hash）：哈希用于存储键值对的无序集合。哈希适合存储对象或实体的属性集合，例如用户信息、文章信息等。
    列表（List）：列表是有序的字符串集合，支持在列表的两端进行元素的插入和删除操作。列表适合用于实现消息队列、任务队列、最新消息列表等场景。
    集合（Set）：集合是无序且唯一的字符串集合，支持对集合进行添加、删除、查找和集合运算等操作。集合适合用于存储不重复的元素，例如标签列表、关注列表等。
    有序集合（Sorted Set）：有序集合是一种有序的集合，每个元素关联着一个分数（score）。有序集合支持按照分数进行排序，并且元素具有唯一性。有序集合适合用于实现排行榜、热门文章列表等。
    地理空间（Geo）：地理空间是Redis 3.2版本引入的数据结构，用于存储地理位置信息和执行地理位置相关的操作。地理空间适合用于实现附近的人、位置检索等应用。
72、Redis 分布式锁底层是如何实现的?
    基于SETNX（Set if Not Exists）命令：SETNX命令用于设置键值对，但只在键不存在的情况下才会设置成功。分布式锁的实现中，可以使用SETNX命令将一个特定的键值对作为锁存储在Redis中，如果SETNX命令返回成功，则表示获取到了锁。在释放锁时，可以使用DEL命令将锁的键删除。这种方式简单直接，但存在死锁问题，当获取锁的客户端执行时间过长或发生异常时，锁无法被及时释放。
    基于Lua脚本的原子操作：Redis支持执行Lua脚本，可以利用Lua脚本的原子性来实现分布式锁。通过执行Lua脚本，可以在Redis中通过SET命令设置一个带有过期时间的键值对作为锁，同时检查该键是否已经被其他客户端占用。如果设置成功，则表示获取到了锁。在释放锁时，可以通过执行Lua脚本删除锁的键，确保操作的原子性。这种方式避免了死锁问题，并提供了更可靠的分布式锁机制。
74、Redis 集群策略
    主从复制（Master-Slave Replication）：使用主从复制策略，将一个Redis节点设置为主节点（Master），其他节点设置为从节点（Slave）。主节点负责写操作，而从节点复制主节点的数据，并处理读请求。当主节点发生故障时，可以将一个从节点晋升为新的主节点，保证系统的高可用性。
    哨兵模式（Sentinel）：哨兵模式是基于主从复制的基础上实现高可用性的策略。它引入了一组哨兵节点，这些节点负责监控主节点的状态。当主节点宕机时，哨兵节点会选举出一个新的主节点，并将其他节点切换为从节点，确保系统的自动故障恢复。
    Redis Cluster（Redis集群）：Redis Cluster是Redis官方推出的分布式解决方案，它通过分区（Sharding）将数据分散存储在多个节点上，实现水平扩展和负载均衡。Redis Cluster支持自动分片、自动故障迁移和自动恢复，提供了高可用性和可扩展性。
    第三方中间件：除了Redis官方提供的集群方案外，还有一些第三方中间件可以实现Redis的集群功能，如Twemproxy、Codis、Pika等。这些中间件提供了额外的功能和扩展，例如代理、路由、数据分片等。
76、Redis 和 Mysql 如何保证数据一致
    Redis和MySQL是两个不同的数据存储系统，它们在数据一致性方面的保证有一些不同的机制和策略。
    读写操作的顺序：在应用程序中，可以通过合理的编码和设计，保证在对Redis和MySQL进行读写操作时的顺序一致性。例如，在进行写操作之后，确保读操作在读取数据之前等待写操作的完成，以确保读取到最新的数据。
    事务机制：MySQL支持事务的概念，可以通过开启事务、执行一系列操作，然后提交事务来保证数据的一致性。如果使用Redis和MySQL作为数据存储，可以使用分布式事务框架（如XA事务）或者应用层面的事务管理来确保Redis和MySQL之间的数据操作的原子性和一致性。
    异步同步机制：Redis和MySQL可以通过异步同步机制来保持数据的一致性。例如，可以通过Redis的发布-订阅机制或者MySQL的binlog来实现数据的异步复制和同步，确保数据在不同存储系统之间的一致性。
    强制同步策略：在某些场景下，可以使用强制同步策略来保证数据一致性。例如，在写操作之后，可以通过Redis的WAIT命令等待持久化操作完成，然后再进行MySQL的写操作，确保数据同时写入Redis和MySQL，并保持一致。
78、Redis 单线程为什么这么快
    避免线程切换开销：在传统的多线程模型中，线程之间的切换会引入一定的开销，包括上下文切换、线程同步等。而Redis采用单线程模型，避免了线程切换的开销，使得系统能够更高效地利用CPU资源。
    内存操作：Redis将数据存储在内存中，因为内存的读写速度远远快于磁盘读写速度。这使得Redis能够快速地处理读写操作，而不受磁盘IO的限制。
    非阻塞IO：Redis使用了非阻塞IO模型，通过使用事件驱动的方式处理网络请求和响应。在等待IO操作完成的过程中，Redis可以继续处理其他请求，提高了系统的并发能力和响应速度。
    精简的功能集：Redis是一个轻量级的键值存储系统，专注于提供高效的数据读写操作。相比于其他复杂的数据库系统，Redis的功能集较为简单，减少了系统的复杂性和开销。
80、什么是 CAP 理论
    CAP理论是分布式系统设计中的一个基本原则，它描述了在分布式系统中的三个核心属性：一致性（Consistency）、可用性（Availability）和分区容错性（Partition Tolerance）之间的权衡关系。CAP理论指出，在一个分布式系统中，不可能同时满足这三个属性的完全一致。
    具体解释如下：
    一致性（Consistency）：指系统中的所有节点在同一时间点上具有相同的数据副本。当一个节点进行数据更新后，所有其他节点在经过一定时间后必须能够获取到最新的数据副本。一致性要求在分布式系统中保持数据的一致性和正确性。
    可用性（Availability）：指系统能够对外提供正常的服务，并在合理的时间范围内响应用户的请求。可用性要求系统在面对故障或异常情况时，仍然能够继续提供部分或全部的功能。
    分区容错性（Partition Tolerance）：指系统能够在网络分区或节点故障的情况下继续运行，并保持对外提供服务。分布式系统由于网络的延迟、故障或其他原因，可能会导致节点之间的通信出现问题或无法访问某些节点。
81、什么是 BASE 理论
    BASE理论是分布式系统设计中的一种理论，它是对ACID（原子性、一致性、隔离性和持久性）原则的一种补充和扩展。BASE是指以下三个概念的缩写：
    基本可用（Basically Available）：系统在面对故障或异常情况时，仍然能够保证基本的可用性，即系统仍能够继续处理请求并提供有限的功能。这意味着系统可以容忍部分故障和性能下降，而不会完全瘫痪。
    软状态（Soft State）：分布式系统中的节点之间的状态并不需要实时一致，即在某一时刻，不同节点的状态可能是不完全一致的。系统允许在一段时间内的状态不一致，但最终会趋向于一致状态。
    最终一致性（Eventually Consistent）：系统中的数据一致性并不要求实时保持一致，而是保证在一定时间内最终达到一致状态。在分布式系统中，数据的复制和同步需要一定的时间，因此系统可以接受一段时间内的数据不一致，但最终会通过某种机制达到一致性。
82、什么是 RPC
    RPC（Remote Procedure Call）是一种远程过程调用的协议，用于实现不同计算机或进程之间的通信和交互。它允许一个计算机程序调用另一个计算机上的函数或方法，就像调用本地函数一样，而不需要开发者关注底层的网络通信细节。
    在RPC中，调用方（通常是客户端）发起一个远程调用请求，包括要调用的函数或方法的名称和参数。这个请求经过网络传输到远程的提供方（通常是服务器），提供方执行对应的函数或方法，并将结果返回给调用方。调用方收到结果后，继续执行后续的操作。
    RPC的实现通常涉及以下几个关键组件：
    通信协议：RPC使用特定的通信协议来定义请求和响应的格式和语义，如XML-RPC、JSON-RPC、gRPC等。通信协议可以基于HTTP、TCP/IP、UDP等不同的网络传输协议。
    接口定义语言（IDL）：IDL用于定义RPC接口和数据类型的规范，以确保调用方和提供方之间的相互理解和兼容性。常见的IDL包括Protocol Buffers、Thrift、Avro等。
    序列化和反序列化：在RPC中，参数和结果通常需要在网络中进行序列化和反序列化，以便在不同的计算机或进程之间传输。序列化将数据对象转换为二进制或其他格式，反序列化将接收到的数据转换回数据对象。
    代理和存根：在一些RPC实现中，代理和存根（Proxy and Stub）扮演着重要的角色。客户端的代理对象负责将函数调用转换为远程调用请求，并处理底层的网络通信。服务器端的存根对象接收请求，并将其转发给实际的函数或方法进行处理。
85、分布式锁的使用场最是什么?有哪些实现方案?
    分布式锁是在分布式系统中用于实现资源的互斥访问的一种机制，它能够确保在多个节点或线程同时访问共享资源时的数据一致性和安全性。分布式锁常见的使用场景包括：
    缓存同步：在分布式缓存环境中，多个节点同时访问同一个缓存项时，可以使用分布式锁来确保只有一个节点能够更新缓存，并防止缓存击穿和雪崩的问题。
    分布式任务调度：在分布式任务调度系统中，多个调度节点可能同时竞争执行同一个任务，使用分布式锁可以确保只有一个节点能够执行任务，避免重复执行和冲突。
    分布式资源访问：在分布式环境中，多个节点可能同时竞争访问共享资源，如数据库、文件系统等。使用分布式锁可以控制对共享资源的互斥访问，防止并发冲突和数据不一致。
    常见的分布式锁实现方案包括：
    基于数据库的实现：使用数据库的事务和锁机制来实现分布式锁。通过在数据库中创建一张特定的表或记录，利用数据库的行级锁或乐观锁来控制对资源的访问。
    基于缓存的实现：利用分布式缓存（如Redis）的原子性操作来实现分布式锁。通过设置一个特定的缓存键作为锁，并利用缓存的原子性操作（如SETNX）来实现锁的获取和释放。
    基于ZooKeeper的实现：利用ZooKeeper提供的有序临时节点（Sequential Ephemeral Node）来实现分布式锁。每个节点尝试创建临时节点，并监视前一个节点的删除事件，以实现对资源的独占访问。
    基于分布式协调框架的实现：使用分布式协调框架（如Apache Curator、Etcd等）提供的分布式锁实现来实现分布式锁。这些框架通常提供了高级的分布式锁实现，具有更强的可靠性和灵活性。
86、什么是分布式事务?有哪些实现方案?
    分布式事务是指涉及多个独立的系统或服务的事务操作，这些系统或服务可能分布在不同的计算节点、数据库或应用程序中。分布式事务需要确保事务的一致性、隔离性、持久性和原子性，以保证多个操作的原子性和一致性。
    在分布式环境下，常见的分布式事务实现方案包括：
    两阶段提交（Two-Phase Commit，2PC）：2PC 是一种经典的分布式事务协调协议。它涉及一个协调者和多个参与者，通过两个阶段的协调和投票来实现事务的提交或回滚。2PC 算法简单易懂，但在网络分区和单点故障等情况下存在性能和可用性问题。
    补偿事务（Compensating Transaction）：补偿事务是一种基于补偿操作的分布式事务实现方案。当某个操作失败时，通过执行一系列相反的补偿操作来回滚事务或修复数据。补偿事务的实现较为灵活，但需要开发者手动编写补偿逻辑，并对业务逻辑进行设计。
    Saga 模式：Saga 是一种分布式事务处理模式，通过一系列局部事务和补偿操作的组合来实现全局事务的一致性。Saga 模式将长事务拆分为一系列短事务，并记录每个事务的状态和补偿操作，以实现事务的可回滚和恢复。
    基于消息的事务（Message-Based Transactions）：通过将事务操作封装为消息，将消息发送到消息队列或消息中间件，并由消息中间件来保证事务的一致性和可靠性。消息中间件通常提供了事务性消息、回查机制和幂等性保证等功能，如 Apache Kafka 和 RabbitMQ。
    最大努力交付（Best-Effort Delivery）：最大努力交付是一种无锁的分布式事务处理模式。它假设系统无法保证完全的一致性，而是尽最大努力地处理事务，通过重试、超时机制和日志记录等手段来保证事务的最终一致性。
95、负载均衢算法有哪些
    负载均衡算法是用于在分布式系统中将请求均匀地分发到多个服务器上，以实现负载均衡和提高系统的性能和可靠性。以下是一些常见的负载均衡算法：
    轮询（Round Robin）算法：按照顺序依次将请求分发给后端服务器，循环往复。适用于后端服务器性能相近的情况。
    权重轮询（Weighted Round Robin）算法：为后端服务器分配不同的权重，按照权重比例将请求分发给服务器。适用于服务器性能不均衡的情况。
    随机（Random）算法：随机选择一个后端服务器来处理请求。适用于后端服务器性能相近且请求无顺序要求的情况。
    最少连接（Least Connections）算法：选择当前连接数最少的后端服务器来处理请求。适用于后端服务器性能不均衡或请求响应时间不同的情况。
    IP哈希（IP Hash）算法：根据客户端的IP地址对后端服务器进行哈希计算，确定请求应该分发到哪个服务器。适用于需要将同一客户端的请求分发到同一服务器的情况，确保会话的一致性。
    最少响应时间（Least Response Time）算法：根据后端服务器的平均响应时间来选择处理请求的服务器。适用于后端服务器响应时间不均衡的情况。
    加权最少响应时间（Weighted Least Response Time）算法：根据后端服务器的平均响应时间和权重来选择处理请求的服务器。适用于需要根据服务器性能和权重进行负载均衡的情况。
96、分布式架构下，Session 共享有什么方案
    在分布式架构下，由于会话（Session）的状态需要在多个服务器之间共享，通常需要采用一些方案来实现会话共享。以下是一些常见的会话共享方案：
    基于数据库：将会话信息存储在共享的数据库中。多个服务器可以访问同一个数据库来读取和更新会话数据。这种方案需要确保数据库的高可用性和性能，同时需要处理并发访问和一致性的问题。
    基于缓存：使用分布式缓存来存储会话数据。常见的分布式缓存系统如Redis和Memcached可以提供高性能的存储和访问，多个服务器可以通过访问共享的缓存来读取和更新会话数据。
    使用共享存储：使用共享文件系统或共享存储来存储会话数据。多个服务器可以通过共享的文件系统或存储访问会话数据。这种方案需要确保文件系统或存储的高可用性和一致性。
    使用专门的会话管理工具：一些分布式会话管理工具，如Spring Session和Apache Shiro等，提供了会话管理的解决方案。这些工具可以将会话信息存储在共享的存储介质中，并提供了会话管理和访问的接口。
    使用反向代理服务器：通过将请求引导到共享的反向代理服务器，反向代理服务器负责管理会话状态。多个服务器可以通过访问共享的反向代理服务器来读取和更新会话数据。常见的反向代理服务器有Nginx和HAProxy等。
97、如何实现接口的冪等性
    接口的幂等性是指无论调用多少次，对系统的状态和数据产生的影响都是一致的。实现接口的幂等性可以确保在面对网络延迟、重试或并发请求时，系统能够保持一致的状态和结果。以下是一些实现接口幂等性的常用方法：
    使用唯一标识符：为每个请求生成唯一的标识符（例如UUID），将该标识符作为请求的一部分发送给服务端。服务端在处理请求时，根据标识符进行幂等性校验，如果发现重复的标识符，可以直接返回之前的处理结果，而无需执行重复的操作。
    版本控制：为每个资源或数据添加版本号，当客户端发送请求时，带上资源或数据的当前版本号。服务端在处理请求时，比较请求中的版本号和当前版本号，如果一致，则执行操作；如果不一致，则拒绝请求或返回冲突信息。
    乐观锁：在数据库或数据存储层面使用乐观锁来控制并发访问。通过在数据记录中添加版本号或时间戳等字段，并在更新操作时对这些字段进行校验，可以避免并发写入时的冲突。
    幂等性检查：在服务端处理请求前，进行幂等性检查。可以根据请求参数、状态变量或数据的唯一标识来判断请求是否已经处理过，如果已经处理过，则直接返回之前的处理结果。
    记录请求日志：记录每个请求的日志，包括请求参数、请求时间等信息。当接收到重复请求时，可以通过查看日志进行判断，并根据需要进行处理。
    使用事务或原子操作：对于涉及多个操作的接口，使用事务或原子操作来确保操作的原子性。如果请求失败或重复提交，可以回滚事务或保证操作的幂等性。
102、雪花算法原理
    雪花算法（Snowflake Algorithm）是一种分布式唯一ID生成算法，可以在分布式系统中生成全局唯一的ID。它的设计目标是在高并发、大规模分布式系统中生成唯一ID，具备足够的性能和扩展性。
    雪花算法的ID由以下几个部分组成：
    时间戳（Timestamp）：使用一个相对时间，一般为当前时间，可以精确到毫秒级。时间戳占用了整个ID的高位，因此生成的ID是趋势递增的。
    机器ID（Machine ID）：用于标识生成ID的机器或节点。在雪花算法中，可以将机器ID分为两部分：数据中心ID和机器ID。数据中心ID用于区分不同的数据中心，而机器ID用于区分同一数据中心下的不同机器。机器ID占用了ID的中间位。
    序列号（Sequence Number）：用于保证同一毫秒内生成的ID在整个系统中唯一。序列号占用了ID的最低位。
    雪花算法的生成过程如下：
    获取当前时间戳，精确到毫秒级。
    判断当前时间戳与上一次生成ID的时间戳是否相同。如果相同，表示在同一毫秒内生成ID，需要增加序列号；如果不同，表示进入下一毫秒，序列号重置为0。
    生成ID，根据时间戳、机器ID和序列号组合而成。具体的位分配可以根据需求和系统规模进行调整。
    雪花算法的优点是生成的ID是趋势递增的、具有时间戳信息、高效且无需依赖外部存储。然而，它也存在一些局限性，例如对系统时钟的依赖性和对机器ID的分配需要考虑等因素。
104、Spring Cloud 有哪些常用组件，作用是什么?
    Eureka：服务注册与发现组件，用于构建服务注册中心，实现服务的自动注册与发现。
    Ribbon：客户端负载均衡组件，用于在服务消费者之间进行负载均衡，实现服务调用的高可用和性能优化。
    Feign：基于Ribbon和动态代理的声明式服务调用组件，简化了服务之间的调用过程，提供了类似于本地方法调用的编程体验。
    Hystrix：容错管理组件，提供了服务降级、服务熔断、请求缓存、请求合并等功能，增强了系统的弹性和容错能力。
    Zuul：网关组件，用于实现服务网关模式，提供动态路由、过滤器链、请求转发等功能，对外暴露统一的API接口。
    Config：分布式配置管理组件，用于集中管理应用程序的配置，实现配置的动态更新和版本控制。
    Bus：消息总线组件，用于在分布式系统中传播配置变化事件，实现配置的动态刷新。
    Sleuth：分布式请求跟踪组件，用于追踪和记录请求在微服务间的传递和调用情况，提供了分布式日志追踪和监控能力。
    Stream：消息驱动组件，用于构建基于消息中间件的微服务应用，提供了统一的消息绑定和消费模型。
    Cloud Bus：用于在分布式系统中传播消息，实现各个节点之间的信息同步。
105、如何避免缓存穿透、缓存击穿。缓存雪崩?
    缓存穿透（Cache Penetration）：缓存穿透是指查询一个不存在的数据，导致缓存无效，请求直接穿透到数据库或后端系统。为了避免缓存穿透，可以使用以下方法：
    布隆过滤器（Bloom Filter）：在缓存层前面引入布隆过滤器，用于快速判断查询的键是否存在于缓存中。如果布隆过滤器判断键不存在，可以直接返回缓存未命中，避免穿透到后端系统。
    空值缓存（Cache Null Values）：当查询的数据不存在时，在缓存中存储一个特殊的标记，表示该数据为空。这样在后续查询相同数据时，可以从缓存中直接返回空值，而不必访问后端系统。
    缓存击穿（Cache Breakdown）：缓存击穿是指一个热点数据过期或失效时，大量并发请求同时访问该数据，导致请求直接落到后端系统，造成系统负载过大。为了避免缓存击穿，可以采取以下方法：
    设置热点数据永不过期：对于热点数据，可以将其缓存时间设置为永不过期，或者设置一个较长的过期时间，确保缓存一直有效，避免因过期而触发大量请求访问后端系统。
    加锁或互斥机制：当缓存失效时，只允许一个请求访问后端系统并更新缓存，其他请求等待该请求完成后再从缓存中获取数据。可以使用分布式锁或互斥机制实现。
    缓存雪崩（Cache Avalanche）：缓存雪崩是指缓存中大量的数据同时过期或失效，导致大量请求直接落到后端系统，造成系统崩溃。为了避免缓存雪崩，可以采取以下方法：
    设置不同的过期时间：将缓存的过期时间设置为稍微不同的时间，避免大量数据同时过期。可以在过期时间上添加一个随机的偏移量，使得缓存的过期时间分散开。
    分布式缓存节点：将缓存分布在多个节点上，使得缓存的失效时间分散开，即使一个节点失效，其他节点仍可以提供缓存服务。
    熔断机制（Circuit Breaking）：在缓存失效时，限制对后端系统的访问，避免大量请求同时打到后端系统。可以通过断路器等机制来实现。
107、缓存过期都有哪些策略?
    定时过期（Time-based Expiration）：为每个缓存项设置一个固定的过期时间，在到达过期时间后自动使缓存项过期，并从缓存中删除。
    惰性过期（Lazy Expiration）：只有在访问缓存项时才检查其过期状态。当访问一个过期的缓存项时，会重新加载或更新该缓存项，使其重新有效，然后再返回给调用方。这种策略可以避免过多的过期检查开销，但可能会导致数据的延迟更新。
    基于访问频率的过期（Access-based Expiration）：根据缓存项的访问频率来判断其是否过期。通过跟踪缓存项的访问次数或时间戳，可以设置一个阈值或时间窗口，如果缓存项在该阈值或时间窗口内没有被访问，则被视为过期并从缓存中删除。
    基于缓存大小的过期（Size-based Expiration）：当缓存空间达到一定的大小限制时，根据一定的策略选择删除一部分缓存项，以便为新的缓存项腾出空间。可以根据缓存项的大小、访问频率等因素来决定哪些缓存项优先删除。
    外部通知过期（External Notification Expiration）：通过接收外部的过期通知来使缓存项过期。外部通知可以来自于数据源或其他相关系统，当数据源更新或发生变化时，发送过期通知给缓存系统，使得相应的缓存项过期并从缓存中删除。
108、常见的缓存淘汰算法
    最近最少使用（Least Recently Used，LRU）：根据数据项的访问时间来淘汰最近最少被使用的数据项。当缓存空间满时，会优先淘汰最久未被访问的数据项。
    最少使用（Least Frequently Used，LFU）：根据数据项的访问频率来淘汰最少被使用的数据项。每次访问数据项时，会增加相应数据项的访问计数，当缓存空间满时，会淘汰访问计数最低的数据项。
    先进先出（First In, First Out，FIFO）：按照数据项进入缓存的顺序来淘汰先进入的数据项。当缓存空间满时，会淘汰最早进入缓存的数据项。
    随机淘汰（Random）：随机选择一个数据项进行淘汰，没有明确的淘汰策略。这种算法简单且容易实现，但不考虑数据项的访问频率或时间。
    最大空间优先（Mostly Recently Used，MRU）：根据数据项的访问时间来淘汰最近被使用的数据项。与LRU相反，MRU算法淘汰最近被访问的数据项。
111、Spring Cloud 和 Dubbo 有哪些区别?
    生态系统：Spring Cloud是基于Spring生态系统构建的，提供了丰富的组件和集成选项，可以与其他Spring项目无缝集成。而Dubbo是阿里巴巴开源的分布式服务框架，它提供了基本的分布式服务治理功能，但在生态系统方面相对较小。
    通信协议：Spring Cloud使用HTTP/REST作为默认的通信协议，通过HTTP接口进行服务之间的通信。Dubbo则采用了自定义的RPC协议，默认使用Dubbo协议进行服务之间的远程调用，通过高效的序列化和网络传输来提高性能。
    服务治理：Spring Cloud提供了多种服务注册与发现的选项，包括Eureka、Consul、Zookeeper等。它还支持负载均衡、断路器、路由等功能。Dubbo也提供了服务注册与发现的功能，但通常与Zookeeper集成。Dubbo还提供了负载均衡、故障转移、流量控制等更多的服务治理功能。
    开发模式：Spring Cloud采用了基于Spring Boot的开发模式，可以通过注解和配置进行快速开发和部署。Dubbo则需要定义接口和实现类，并使用XML或注解进行配置，需要更多的显式开发和配置。
    适用场景：Spring Cloud适用于构建微服务架构的应用程序，特别适合与Spring生态系统的其他组件和库进行集成。Dubbo则更适合于大规模分布式系统中的服务治理和远程调用场景，特别适合于阿里巴巴的应用开发
112、什么是服务雪崩?什么是服务限流?
    服务雪崩（Service Avalanche）是指在分布式系统中，当一个或多个服务出现故障或不可用时，导致对其他服务的请求积累并最终超过其负载能力，从而导致整个系统崩溃的情况。服务雪崩通常是由于缺乏适当的容错机制和故障处理策略导致的。
    服务限流（Service Rate Limiting）是一种控制系统中请求流量的策略。通过设置请求的速率上限，服务限流可以防止过多的请求进入系统，保护系统免受过载和崩溃的风险。服务限流可以基于时间窗口、并发连接数、请求频率等指标来进行限制，确保系统资源的合理分配和稳定运行。
113、什么是服务熔断?什么是服务降级?区别是什么?
    服务熔断（Circuit Breaker）是一种用于处理服务故障的模式。在分布式系统中，当某个服务出现故障或延迟超过预设阈值时，服务熔断会将该服务的调用进行临时断开，避免对整个系统造成更大的延迟或故障。熔断器会在服务发生故障时迅速断开请求，而不会等待超时。当服务熔断后，可以使用一种备用方案（例如返回默认值或错误信息）来代替对故障服务的调用。服务熔断还可以监控服务的状态，并在故障恢复后重新连接。
    服务降级（Service Degradation）是一种通过牺牲一些功能或质量以保证核心功能的可用性的策略。当系统面临资源紧张、高负载或其他异常情况时，服务降级可以主动减少某些服务或功能的响应速度或质量，以确保核心功能的可用性。例如，在高负载情况下，可以暂时关闭一些不太重要的功能或限制某些服务的请求频率，以保证系统的稳定性和可用性
114、SOA、分布式，微服务之间有什么关系和区别?
    SOA是一种软件架构风格，它将应用程序设计为一组松散耦合的服务，这些服务通过标准化的接口进行通信。每个服务代表着特定的业务功能，可以独立开发、部署和扩展。SOA强调服务的可重用性、松散耦合和组合性。
    分布式系统是指将计算机系统的组件和资源分布在多个计算机或节点上，这些节点通过网络进行通信和协调。分布式系统的目标是将计算任务和数据分散处理，以提高性能、可靠性和扩展性。分布式系统可以包含多个服务，并使用网络进行服务之间的通信。
    微服务是一种架构模式，旨在通过将应用程序拆分为一组小型、自治的服务来解决复杂的应用程序开发和维护问题。每个微服务专注于单个业务功能，并通过独立部署、独立扩展和松散耦合的方式进行开发。微服务之间通过API进行通信，每个微服务可以使用不同的技术栈和编程语言。
119、你的项目中是怎么保证微服务敏捷开发的?
    划分合适的微服务边界：将系统划分为较小的、松耦合的服务单元，每个服务负责一个明确的业务功能。这样可以提高开发团队的自治性和独立性，使其能够快速迭代和交付。
    自动化部署和持续集成：采用自动化工具和流程，实现持续集成和持续部署。通过自动化测试、构建和部署，可以确保代码变更能够快速且可靠地发布到生产环境中。
    敏捷开发方法论：采用敏捷开发方法论，如Scrum或Kanban，通过迭代开发和精益流程来增强团队的敏捷性。团队成员可以根据优先级和价值，快速响应需求变更，并持续交付有价值的软件
    高度自动化的测试：在微服务架构中，每个服务都需要进行独立的单元测试和集成测试。自动化测试可以帮助检测潜在问题，并快速回归验证服务的功能和性能。
    服务治理和监控：采用适当的服务治理和监控机制，可以帮助团队快速识别和解决服务中的问题。监控指标和日志记录可以提供实时的反馈和可见性，以便及时采取行动。
    弹性和可伸缩性设计：在设计微服务时，考虑到弹性和可伸缩性是至关重要的。这意味着在高负载情况下，服务能够自动扩展以应对压力，并在出现故障时能够优雅地降级或恢复。
    高效的团队协作：通过良好的团队协作和沟通，可以加速开发过程。使用协作工具、定期的迭代计划会议和持续的反馈循环，确保团队成员之间的合作和信息共享。
123、rabbitMQ 的实现原理
    发布和订阅：消息的发布者将消息发送到 RabbitMQ 的交换机（Exchange），交换机根据特定的路由规则将消息转发到一个或多个队列中。订阅者通过绑定队列到交换机，从相应的队列中接收消息。
    消息队列：RabbitMQ 使用消息队列来存储和缓冲消息，待消费者准备好时再进行投递。队列是消息的主要存储区域，消息按照先进先出（FIFO）的顺序进行处理。
    路由和绑定：交换机根据消息的路由键（Routing Key）将消息路由到相应的队列。订阅者可以根据需要将队列绑定到交换机，并指定路由键和其他参数，以满足特定的消息路由规则。
    消费者和消费确认：消费者从队列中获取消息，并进行处理。处理完成后，消费者向 RabbitMQ 发送消费确认（ACK）消息，告知 RabbitMQ 已经成功消费了该消息。RabbitMQ 根据消费确认的情况，决定是否从队列中删除消息。
    消息持久化：RabbitMQ 支持消息的持久化存储，以防止消息丢失。消息持久化是通过将消息和队列标记为持久化来实现的，这样即使在 RabbitMQ 服务器重启后，之前发送的消息仍然可以被恢复和重新处理。
    负载均衡和高可用性：RabbitMQ 支持集群部署，多个 RabbitMQ 节点可以组成一个集群，共同提供服务。集群中的节点可以共享队列和消息，并通过负载均衡的方式进行消息的分发，从而提高系统的可扩展性和高可用性。
    消息确认机制：RabbitMQ 支持消息的可靠传输，通过消费者的消费确认机制来实现。当消费者成功处理一条消息后，会向 RabbitMQ 发送消费确认。只有在收到消费确认后，RabbitMQ 才会将消息从队列中删除，确保消息不会丢失。
    插件和扩展性：RabbitMQ 提供了丰富的插件机制，可以扩展其功能和特性。例如，可以通过插件实现消息的延时发送、消息的优先级排序、消息的事务支持等。
124、rabbitMQ 为什么速度快
    异步处理：RabbitMQ 是一个异步消息队列系统，它使用了高效的异步机制来处理消息的发送和接收。异步处理意味着消息发送者无需等待消息接收者的响应，可以继续执行其他任务，从而提高系统的并发性和吞吐量。
    消息持久化和确认机制：RabbitMQ 支持消息的持久化存储和确认机制。持久化消息可以保证消息在发送后不会丢失，即使在发生故障或重启后仍然可以被恢复和重新处理。确认机制确保只有当消息成功被接收方确认后，才将消息从队列中删除，避免消息的丢失。
    高效的消息路由：RabbitMQ 使用 AMQP（Advanced Message Queuing Protocol）作为消息传输协议，具备灵活且高效的消息路由机制。AMQP 的路由机制可以根据消息的属性、内容和目标队列进行灵活的路由和过滤，提高消息的处理效率。
    高可靠性和故障恢复：RabbitMQ 提供了高可靠性的消息传输保证，支持多种故障恢复机制。例如，它可以在节点故障后自动进行故障转移，确保消息队列的可用性和持久性。此外，RabbitMQ 还支持集群部署，提供了高可用性和负载均衡的能力。
    多种消息传输模式：RabbitMQ 支持多种消息传输模式，例如发布-订阅模式、点对点模式和工作队列模式。这些不同的模式可以满足不同场景下的消息传输需求，并提供了更高的灵活性和效率。
    轻量级和高性能：RabbitMQ 是一个轻量级的消息队列系统，具有高性能和低延迟的特点。它使用 Erlang 编程语言实现，Erlang 的并发和分布式特性使得 RabbitMQ 在处理大量消息时能够具备出色的性能。
125、消息队列如何保证消息可靠传输
    持久化消息：消息队列通常提供消息持久化的机制，确保消息在发送后不会丢失。这意味着即使在消息发送到队列后，但在被消费者接收之前，消息仍然会被持久化存储在磁盘上。即使系统发生故障或重启，之前发送的消息可以被恢复和重新处理，保证消息不会丢失。
    确认机制（Acknowledgement）：消息队列支持消费者发送确认机制，消费者在接收和处理完一条消息后，会向消息队列发送确认信息。只有当消息队列收到消费者的确认后，才会将该消息从队列中删除。这种机制确保消息在被成功处理之前不会丢失。
    重试机制：当消息无法被消费者正确处理时，消息队列可以支持消息的自动重试机制。当消费者无法处理消息或发生错误时，消息队列可以将消息重新发送给消费者，直到消费者成功处理为止。通过重试机制，可以确保消息的可靠传输和处理。
    错误处理和死信队列：当消息无法被正常消费时，例如消费者无法处理消息或消息超时等，消息队列可以将这些无法处理的消息发送到特殊的死信队列中。这样可以对无法正常处理的消息进行集中处理和跟踪，以便进一步分析和处理。
    可靠的传输协议：消息队列通常使用可靠的传输协议，例如TCP/IP，以确保消息在网络传输过程中不会丢失或被损坏。这种传输协议提供了数据完整性和可靠性的保证，确保消息可以安全地传输到目标队列。
    事务支持：一些消息队列系统支持事务机制，允许发送和接收消息在一个事务中进行操作。如果在事务提交之前发生错误，整个操作将被回滚，消息不会被发送或接收。这种机制可以确保消息的可靠传输和一致性。
126、消息队列有哪些作用
    解耦应用系统：通过引入消息队列，不同的应用系统可以通过消息的发送和接收来进行解耦。发送方将消息发送到队列中，而不需要直接与接收方进行耦合。这样可以提高系统的灵活性和可维护性，允许各个系统独立演化和扩展。
    异步通信：消息队列提供了异步通信的机制，发送方可以将消息发送到队列中，而无需等待接收方的响应。这样可以实现解耦和提高系统的响应速度。例如，一个系统可以将耗时的任务放入消息队列中，然后由另一个系统异步地进行处理。
    削峰填谷：在高峰期，消息队列可以用来平滑处理系统的流量。当系统无法立即处理所有请求时，请求可以暂时存储在消息队列中，然后逐渐处理。这样可以防止系统过载和崩溃，提高系统的稳定性和可靠性。
    消息持久化：消息队列通常提供消息持久化的机制，确保消息在发送后不会丢失。即使系统发生故障或重启，之前发送的消息仍然可以被恢复和处理。这对于一些对数据可靠性要求较高的应用场景非常重要。
    广播和订阅：消息队列可以支持广播和订阅模型，一个消息可以被多个订阅者同时接收。这对于实现发布-订阅模式和实时信息传递非常有用。订阅者可以订阅感兴趣的消息主题，而不需要直接和发布者进行通信。
    顺序性保证：一些消息队列系统可以提供消息的顺序性保证，即相同的发送顺序将被保留并按照相同的顺序传递给接收方。这对于某些需要严格顺序处理的应用场景非常重要，例如订单处理、日志记录等。
127、死信队列是什么?延时队列是什么?
    死信队列（Dead Letter Queue）是消息队列中的一种特殊队列，用于存储无法被消费者正确处理的消息。当一条消息无法被正常消费时（例如消费者无法处理消息、消息超时等），消息会被发送到死信队列中，以便进一步分析和处理。
    使用死信队列的好处是，可以对无法正常处理的消息进行集中处理和跟踪。通过查看死信队列中的消息，可以分析出问题所在，并采取相应的措施，例如重新发送消息、人工处理等。死信队列还可以用于实现消息重试机制，让系统能够自动处理一些临时的故障。
    延时队列（Delay Queue）是一种特殊的消息队列，用于延迟发送消息。在延时队列中，消息发送后并不会立即被消费者接收到，而是经过一定的延迟时间后才能被消费。延时队列常用于实现一些具有定时任务或延迟触发的功能。
    当消息被发送到延时队列中，可以指定一个延迟时间。在经过指定的延迟时间后，消息会被转移到正常的消息队列中，然后被消费者处理。延时队列可以用于实现诸如消息重试、定时任务、延迟通知等应用场景。
    延时队列的实现方式可以有多种，例如在消息队列系统中直接支持延时队列，或者使用定时任务和定时器来模拟延时发送。无论哪种方式，延时队列都提供了一种便捷的方式来实现消息的延迟处理。
128、如何保证消息的高效读写?
    使用合适的消息队列系统：选择一个适合您需求的消息队列系统，例如 RabbitMQ、Apache Kafka、ActiveMQ 等。不同的消息队列系统具有不同的特性和适用场景，您可以根据您的需求进行评估和选择。
    异步处理：将读写操作异步化，即发送消息和接收消息的过程不需要等待对方的响应。这样可以提高消息的吞吐量和响应速度。您可以使用异步消息发送和消费的方式，例如使用异步发送者和异步消费者模式。
    批量处理：将消息批量发送或批量消费，而不是一条一条地处理。这可以减少网络开销和系统调用次数，提高效率。例如，可以将多个相关的消息打包为一个批次发送到消息队列，然后一次性消费这个批次的消息。
    使用消息分区：对于高负载的系统，您可以将消息分区到多个队列或主题中。这样可以实现消息的并行处理，提高读写的效率。根据消息的特性，将其分配到不同的分区，可以使得消息在多个消费者之间更加均衡地分布。
    考虑消息持久化：将消息持久化存储可以保证消息在系统故障或重启后的可靠性。消息队列系统通常提供消息持久化的机制，确保消息在发送后不会丢失。这样即使系统出现故障，消息也可以在系统恢复后被重新处理。
    优化网络和硬件配置：对于分布式的消息队列系统，优化网络和硬件配置也是提高读写效率的重要因素。确保网络连接稳定，减少网络延迟。同时，根据系统负载和需求，适当调整硬件配置，包括服务器性能、存储容量等。
129、epoll 和 poll 的区别
    epoll和poll都是在Linux系统中用于实现事件驱动的I/O多路复用的机制，它们的主要区别如下：
    效率和性能： epoll在处理大量并发连接时性能更好，因为epoll使用了事件通知方式，只会将就绪的事件通知给应用程序，而不需要遍历所有的文件描述符。相比之下，poll需要遍历所有的文件描述符来找到就绪的事件。
    可扩展性： epoll对于大规模的并发连接更具可扩展性。它使用了事件驱动的方式，能够高效地处理成千上万的并发连接，而poll在处理大量并发连接时性能会有所下降。
    触发方式： epoll提供了两种触发方式：边缘触发（Edge-Triggered）和水平触发（Level-Triggered），而poll只支持水平触发。在边缘触发模式下，只有当状态发生变化时才会触发事件通知，而在水平触发模式下，只要状态处于就绪状态，就会不断触发事件通知。
    API调用方式： epoll和poll的API调用方式略有不同。epoll使用三个API：epoll_create创建一个epoll实例，epoll_ctl用于添加、修改或删除事件，epoll_wait用于等待就绪的事件。而poll只使用一个API：poll。
    总的来说，epoll相对于poll在性能和可扩展性上有着明显的优势，特别适用于处理高并发的网络应用。然而，需要注意的是epoll是Linux特有的机制，在其他操作系统上可能不可用，而poll则是跨平台的。因此，在选择使用epoll或poll时，需要考虑到目标平台的兼容性需求。
130、TCP 的三次握手和四次挥手
    三次握手建立连接的过程如下：
    第一步（SYN）：客户端发送一个带有SYN（同步）标志的TCP报文段，指定客户端的初始序列号（ISN）。
    客户端：发送位于初始序列号（ISN）位置的SYN标志，表示请求建立连接。
    服务器：接收到客户端的SYN报文段后，为该连接分配资源，发送一个带有SYN和ACK（确认）标志的TCP报文段作为应答。
    第二步（SYN+ACK）：服务器接收到客户端的SYN报文段后，发送一个带有SYN和ACK标志的TCP报文段作为响应，确认连接请求，并指定服务器的初始序列号（ISN）。
    服务器：发送位于初始序列号（ISN）位置的SYN和ACK标志，表示接受客户端的连接请求并确认连接。
    客户端：接收到服务器的SYN+ACK报文段后，向服务器发送一个带有ACK标志的TCP报文段作为确认。
    第三步（ACK）：客户端接收到服务器的SYN+ACK报文段后，发送一个带有ACK标志的TCP报文段作为最后的确认，完成三次握手。
    客户端：发送位于服务器ISN+1位置的ACK标志，表示确认服务器的连接响应。
    服务器：接收到客户端的ACK报文段后，确认客户端的确认，此时连接建立完成。
    四次挥手关闭连接的过程如下：
    第一步（FIN）：一个应用程序发送一个带有FIN（结束）标志的TCP报文段，希望关闭连接。
    客户端/服务器：发送位于序列号位置的FIN标志，表示希望关闭连接。
    第二步（ACK）：对方接收到FIN后，发送一个带有ACK标志的TCP报文段作为确认。
    服务器/客户端：发送位于序列号位置的ACK标志，表示确认对方的关闭请求。
    第三步（FIN）：对方收到确认后，会发送一个带有FIN标志的TCP报文段，表示自己也希望关闭连接。
    客户端/服务器：发送位于序列号位置的FIN标志，表示希望关闭连接。
    第四步（ACK）：接收到FIN后，对方发送一个带有ACK标志的TCP报文段作为确认，确认关闭连接。
    服务器/客户端：发送位于序列号位置的ACK标志，表示确认对方的关闭请求。
131、浏览器发出一个请求到收到响应经历了哪些步骤?
    用户输入URL或点击链接：用户在浏览器地址栏中输入URL或点击页面上的链接，触发请求的发起。
    DNS解析：浏览器提取URL中的主机名，并向本地DNS服务器发送请求以获取主机的IP地址。如果本地DNS服务器没有缓存对应的IP地址，则会向其他DNS服务器进行递归查询，直到找到对应的IP地址。
    建立TCP连接：浏览器使用获取到的IP地址与服务器建立TCP连接。这个过程通常涉及三次握手，即浏览器向服务器发送SYN报文，服务器回复SYN-ACK报文，最后浏览器发送ACK报文，建立起双向的TCP连接。
    发送HTTP请求：浏览器通过TCP连接向服务器发送HTTP请求。请求包括请求方法（GET、POST等）、请求头（如User-Agent、Cookie等）以及请求体（对于POST请求）等信息。
    服务器处理请求：服务器接收到请求后，根据请求的URL、请求方法等进行处理。处理的具体过程可能包括路由匹配、处理业务逻辑、查询数据库等。
    服务器发送HTTP响应：服务器根据请求处理的结果生成HTTP响应。响应包括响应状态码（如200表示成功，404表示资源未找到等）、响应头（如Content-Type、Cache-Control等）以及响应体（包含返回的数据）等信息。
    接收HTTP响应：浏览器接收到服务器发送的HTTP响应。
    解析和渲染响应内容：浏览器对接收到的响应进行解析和渲染，将响应的HTML、CSS、JavaScript等内容转化为可视化的页面。
    关闭TCP连接：当页面渲染完成后，浏览器会关闭与服务器之间的TCP连接，释放相关资源
132、跨域请求是什么?有什么问题?怎么解决?
    跨域请求（Cross-Origin Request）指的是在Web应用程序中，通过JavaScript在一个域（Domain）下发送HTTP请求到另一个域的情况。跨域请求是由浏览器的同源策略（Same-Origin Policy）所限制的，同源策略要求网页的源（协议、域名和端口）必须与目标资源的源相同，否则浏览器会阻止跨域请求。
    跨域请求可能会遇到以下问题：
    XMLHttpRequest 和 Fetch 请求受到同源策略的限制，无法跨域发送请求。
    跨域的脚本无法获取和操作目标域下的 DOM。
    跨域的 Ajax 请求会被浏览器拦截，导致请求失败。
    跨域的 Cookie 无法在浏览器中自动发送，导致身份验证等功能受到影响。
    为了解决跨域请求的问题，可以采取以下方法：
    JSONP（JSON with Padding）：通过动态创建<script>标签，利用<script>标签没有跨域限制的特性，在请求中指定回调函数，服务器返回的数据将作为回调函数的参数传递。
    CORS（Cross-Origin Resource Sharing）：服务器在响应头中设置特定的CORS标头，允许指定的源访问资源，从而解除跨域限制。常见的CORS标头包括Access-Control-Allow-Origin、Access-Control-Allow-Methods、Access-Control-Allow-Headers等。
    代理服务器：在同源策略下，通过在服务器端添加代理来转发请求，实现跨域请求。前端发送请求到同源的服务器，服务器再将请求发送到目标域，将响应返回给前端。
    WebSocket：WebSocket协议允许在不受同源策略限制的情况下，在客户端与服务器之间建立持久化的连接，实现实时数据通信。
133、零拷贝是什么
    当数据从一个缓冲区（如文件、网络或内存）复制到另一个缓冲区时，通常需要经过两次数据复制。首先，数据从源缓冲区复制到操作系统内核缓冲区，然后再从内核缓冲区复制到目标缓冲区。这两次复制会导致额外的CPU和内存开销。
    而零拷贝技术通过避免数据的中间复制，直接在源和目标之间传输数据，来减少复制次数和开销。这意味着数据可以直接从源缓冲区发送到目标缓冲区，而无需中间的内核缓冲区，从而减少了CPU的参与和数据移动的开销。
    在Java中，零拷贝通常使用java.nio包中的ByteBuffer类来实现。ByteBuffer提供了一种直接的内存访问方式，可以通过内存映射文件、直接内存分配等方式实现零拷贝。
docker的工作原理是什么，讲一下
    docker是一个Client-Server结构的系统，docker守护进程运行在宿主机上，守护进程从客户端接受命令并管理运行在主机上的容器，容器是一个运行时环境，这就是我们说的集装箱。
docker的组成包含哪几大部分
    一个完整的docker有以下几个部分组成：
    1、docker client，客户端，为用户提供一系列可执行命令，用户用这些命令实现跟 docker daemon 交互；
    2、docker daemon，守护进程，一般在宿主主机后台运行，等待接收来自客户端的请求消息；
    3、docker image，镜像，镜像run之后就生成为docker容器；
    4、docker container，容器，一个系统级别的服务，拥有自己的ip和系统目录结构；运行容器前需要本地存在对应的镜像，如果本地不存在该镜像则就去镜像仓库下载。
    docker 使用客户端-服务器 (C/S) 架构模式，使用远程api来管理和创建docker容器。docker 容器通过 docker 镜像来创建。容器与镜像的关系类似于面向对象编程中的对象与类。
docker与传统虚拟机的区别什么？
    1、传统虚拟机是需要安装整个操作系统的，然后再在上面安装业务应用，启动应用，通常需要几分钟去启动应用，而docker是直接使用镜像来运行业务容器的，其容器启动属于秒级别；
    2、Docker需要的资源更少，Docker在操作系统级别进行虚拟化，Docker容器和内核交互，几乎没有性能损耗，而虚拟机运行着整个操作系统，占用物理机的资源就比较多;
    3、Docker更轻量，Docker的架构可以共用一个内核与共享应用程序库，所占内存极小;同样的硬件环境，Docker运行的镜像数远多于虚拟机数量，对系统的利用率非常高;
    4、与虚拟机相比，Docker隔离性更弱，Docker属于进程之间的隔离，虚拟机可实现系统级别隔离;
    5、Docker的安全性也更弱，Docker的租户root和宿主机root相同，一旦容器内的用户从普通用户权限提升为root权限，它就直接具备了宿主机的root权限，进而可进行无限制的操作。虚拟机租户root权限和宿主机的root虚拟机权限是分离的，并且虚拟机利用如Intel的VT-d和VT-x的ring-1硬件隔离技术，这种技术可以防止虚拟机突破和彼此交互，而容器至今还没有任何形式的硬件隔离;
    6、Docker的集中化管理工具还不算成熟，各种虚拟化技术都有成熟的管理工具，比如：VMware vCenter提供完备的虚拟机管理能力;
    7、Docker对业务的高可用支持是通过快速重新部署实现的，虚拟化具备负载均衡，高可用、容错、迁移和数据保护等经过生产实践检验的成熟保障机制，Vmware可承诺虚拟机99.999%高可用，保证业务连续性;
    8、虚拟化创建是分钟级别的，Docker容器创建是秒级别的，Docker的快速迭代性，决定了无论是开发、测试、部署都可以节省大量时间;
    9、虚拟机可以通过镜像实现环境交付的一致性，但镜像分发无法体系化，Docker在Dockerfile中记录了容器构建过程，可在集群中实现快速分发和快速部署。
docker技术的三大核心概念是什么？
    镜像：镜像是一种轻量级、可执行的独立软件包，它包含运行某个软件所需的所有内容，我们把应用程序和配置依赖打包好形成一个可交付的运行环境(包括代码、运行时需要的库、环境变量和配置文件等)，这个打包好的运行环境就是image镜像文件。
    容器：容器是基于镜像创建的，是镜像运行起来之后的一个实例，容器才是真正运行业务程序的地方。如果把镜像比作程序里面的类，那么容器就是对象。
    镜像仓库：存放镜像的地方，研发工程师打包好镜像之后需要把镜像上传到镜像仓库中去，然后就可以运行有仓库权限的人拉取镜像来运行容器了。
centos镜像几个G，但是docker centos镜像才几百兆，这是为什么？
    一个完整的Linux操作系统包含Linux内核和rootfs根文件系统，即我们熟悉的/dev、/proc/、/bin等目录。我们平时看到的centOS除了rootfs，还会选装很多软件，服务，图形桌面等，所以centOS镜像有好几个G也不足为奇。
    而对于容器镜像而言，所有容器都是共享宿主机的Linux 内核的，而对于docker镜像而言，docker镜像只需要提供一个很小的rootfs即可，只需要包含最基本的命令，工具，程序库即可，所有docker镜像才会这么小。
讲一下镜像的分层结构以及为什么要使用镜像的分层结构？
    一个新的镜像其实是从 base 镜像一层一层叠加生成的。每安装一个软件，dockerfile中使用RUM命令，就会在现有镜像的基础上增加一层，这样一层一层的叠加最后构成整个镜像。所以我们docker pull拉取一个镜像的时候会看到docker是一层层拉去的。
    分层机构最大的一个好处就是 ： 共享资源。比如：有多个镜像都从相同的 base 镜像构建而来，那么 Docker Host 只需在磁盘上保存一份 base 镜像；同时内存中也只需加载一份 base 镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享。
讲一下容器的copy-on-write特性，修改容器里面的内容会修改镜像吗？
    我们知道，镜像是分层的，镜像的每一层都可以被共享，同时，镜像是只读的。当一个容器启动时，一个新的可写层被加载到镜像的顶部，这一层通常被称作“容器层”，“容器层”之下的都叫“镜像层”。
    所有对容器的改动 - 无论添加、删除、还是修改文件，都只会发生在容器层中，因为只有容器层是可写的，容器层下面的所有镜像层都是只读的。镜像层数量可能会很多，所有镜像层会联合在一起组成一个统一的文件系统。如果不同层中有一个相同路径的文件，比如 /a，上层的 /a 会覆盖下层的 /a，也就是说用户只能访问到上层中的文件 /a。在容器层中，用户看到的是一个叠加之后的文件系统。
    添加文件时：在容器中创建文件时，新文件被添加到容器层中。
    读取文件：在容器中读取某个文件时，Docker 会从上往下依次在各镜像层中查找此文件。一旦找到，立即将其复制到容器层，然后打开并读入内存。
    修改文件：在容器中修改已存在的文件时，Docker 会从上往下依次在各镜像层中查找此文件。一旦找到，立即将其复制到容器层，然后修改之。
    删除文件：在容器中删除文件时，Docker 也是从上往下依次在镜像层中查找此文件。找到后，会在容器层中记录下此删除操作。
    只有当需要修改时才复制一份数据，这种特性被称作 Copy-on-Write。可见，容器层保存的是镜像变化的部分，不会对镜像本身进行任何修改。
简单描述一下Dockerfile的整个构建镜像过程
    1、首先，创建一个目录用于存放应用程序以及构建过程中使用到的各个文件等；
    2、然后，在这个目录下创建一个Dockerfile文件，一般建议Dockerfile的文件名就是Dockerfile；
    3、编写Dockerfile文件，编写指令，如，使用FROM 指令指定基础镜像，COPY指令复制文件，RUN指令指定要运行的命令，ENV设置环境变量，EXPOSE指定容器要暴露的端口，WORKDIR设置当前工作目录，CMD容器启动时运行命令，等等指令构建镜像；
    4、Dockerfile编写完成就可以构建镜像了，使用docker build -t 镜像名:tag . 命令来构建镜像，最后一个点是表示当前目录，docker会默认寻找当前目录下的Dockerfile文件来构建镜像，如果不使用默认，可以使用-f参数来指定dockerfile文件，如：docker build -t 镜像名:tag -f /xx/xxx/Dockerfile ；
    5、使用docker build命令构建之后，docker就会将当前目录下所有的文件发送给docker daemon，顺序执行Dockerfile文件里的指令，在这过程中会生成临时容器，在临时容器里面安装RUN指定的命令，安装成功后，docker底层会使用类似于docker commit命令来将容器保存为镜像，然后删除临时容器，以此类推，一层层的构建镜像，运行临时容器安装软件，直到最后的镜像构建成功。
Dockerfile构建镜像出现异常，如何排查？
    首先，Dockerfile是一层一层的构建镜像，期间会产生一个或多个临时容器，构建过程中其实就是在临时容器里面安装应用，如果因为临时容器安装应用出现异常导致镜像构建失败，这时容器虽然被清理掉了，但是期间构建的中间镜像还在，那么我们可以根据异常时上一层已经构建好的临时镜像，将临时镜像运行为容器，然后在容器里面运行安装命令来定位具体的异常。
Dockerfile的基本指令有哪些？
    FROM 指定基础镜像（必须为第一个指令，因为需要指定使用哪个基础镜像来构建镜像）；
    MAINTAINER 设置镜像作者相关信息，如作者名字，日期，邮件，联系方式等；
    COPY 复制文件到镜像；
    ADD 复制文件到镜像（ADD与COPY的区别在于，ADD会自动解压tar、zip、tgz、xz等归档文件，而COPY不会，同时ADD指令还可以接一个url下载文件地址，一般建议使用COPY复制文件即可，文件在宿主机上是什么样子复制到镜像里面就是什么样子这样比较好）；
    ENV 设置环境变量；
    EXPOSE 暴露容器进程的端口，仅仅是提示别人容器使用的哪个端口，没有过多作用；
    VOLUME 数据卷持久化，挂载一个目录；
    WORKDIR 设置工作目录，如果目录不在，则会自动创建目录；
    RUN 在容器中运行命令，RUN指令会创建新的镜像层，RUN指令经常被用于安装软件包；
    CMD 指定容器启动时默认运行哪些命令，如果有多个CMD，则只有最后一个生效，另外，CMD指令可以被docker run之后的参数替换；
    ENTRYOINT 指定容器启动时运行哪些命令，如果有多个ENTRYOINT，则只有最后一个生效，另外，如果Dockerfile中同时存在CMD和ENTRYOINT，那么CMD或docker run之后的参数将被当做参数传递给ENTRYOINT；

k8s的组件有哪些，作用分别是什么？
    k8s主要由master节点和node节点构成。master节点负责管理集群，node节点是容器应用真正运行的地方。
    master节点包含的组件有：kube-api-server、kube-controller-manager、kube-scheduler、etcd。
    node节点包含的组件有：kubelet、kube-proxy、container-runtime。
    kube-api-server：以下简称api-server，api-server是k8s最重要的核心组件之一，它是k8s集群管理的统一访问入口，提供了RESTful API接口, 实现了认证、授权和准入控制等安全功能；api-server还是其他组件之间的数据交互和通信的枢纽，其他组件彼此之间并不会直接通信，其他组件对资源对象的增、删、改、查和监听操作都是交由api-server处理后，api-server再提交给etcd数据库做持久化存储，只有api-server才能直接操作etcd数据库，其他组件都不能直接操作etcd数据库，其他组件都是通过api-server间接的读取，写入数据到etcd。
    kube-controller-manager：以下简称controller-manager，controller-manager是k8s中各种控制器的的管理者，是k8s集群内部的管理控制中心，也是k8s自动化功能的核心；controller-manager内部包含replication controller、node controller、deployment controller、endpoint controller等各种资源对象的控制器，每种控制器都负责一种特定资源的控制流程，而controller-manager正是这些controller的核心管理者。
    kube-scheduler：以下简称scheduler，scheduler负责集群资源调度，其作用是将待调度的pod通过一系列复杂的调度算法计算出最合适的node节点，然后将pod绑定到目标节点上。shceduler会根据pod的信息，全部节点信息列表，过滤掉不符合要求的节点，过滤出一批候选节点，然后给候选节点打分，选分最高的就是最佳节点，scheduler就会把目标pod安置到该节点。
    Etcd：etcd是一个分布式的键值对存储数据库，主要是用于保存k8s集群状态数据，比如，pod，service等资源对象的信息；etcd可以是单个也可以有多个，多个就是etcd数据库集群，etcd通常部署奇数个实例，在大规模集群中，etcd有5个或7个节点就足够了；另外说明一点，etcd本质上可以不与master节点部署在一起，只要master节点能通过网络连接etcd数据库即可。
    kubelet：每个node节点上都有一个kubelet服务进程，kubelet作为连接master和各node之间的桥梁，负责维护pod和容器的生命周期，当监听到master下发到本节点的任务时，比如创建、更新、终止pod等任务，kubelet 即通过控制docker来创建、更新、销毁容器；
    每个kubelet进程都会在api-server上注册本节点自身的信息，用于定期向master汇报本节点资源的使用情况。
    kube-proxy：kube-proxy运行在node节点上，在Node节点上实现Pod网络代理，维护网络规则和四层负载均衡工作，kube-proxy会监听api-server中从而获取service和endpoint的变化情况，创建并维护路由规则以提供服务IP和负载均衡功能。简单理解此进程是Service的透明代理兼负载均衡器，其核心功能是将到某个Service的访问请求转发到后端的多个Pod实例上。
    container-runtime：容器运行时环境，即运行容器所需要的一系列程序，目前k8s支持的容器运行时有很多，如docker、rkt或其他，比较受欢迎的是docker，但是新版的k8s已经宣布弃用docker。
kubelet的功能、作用是什么？（重点，经常会问）
    答：kubelet部署在每个node节点上的，它主要有2个功能：
    1、节点管理。kubelet启动时会向api-server进行注册，然后会定时的向api-server汇报本节点信息状态，资源使用状态等，这样master就能够知道node节点的资源剩余，节点是否失联等等相关的信息了。master知道了整个集群所有节点的资源情况，这对于 pod 的调度和正常运行至关重要。
    2、pod管理。kubelet负责维护node节点上pod的生命周期，当kubelet监听到master的下发到自己节点的任务时，比如要创建、更新、删除一个pod，kubelet 就会通过CRI（容器运行时接口）插件来调用不同的容器运行时来创建、更新、删除容器；常见的容器运行时有docker、containerd、rkt等等这些容器运行时，我们最熟悉的就是docker了，但在新版本的k8s已经弃用docker了，k8s1.24版本中已经使用containerd作为容器运行时了。
    3、容器健康检查。pod中可以定义启动探针、存活探针、就绪探针等3种，我们最常用的就是存活探针、就绪探针，kubelet 会定期调用容器中的探针来检测容器是否存活，是否就绪，如果是存活探针，则会根据探测结果对检查失败的容器进行相应的重启策略；
    4、Metrics Server资源监控。在node节点上部署Metrics Server用于监控node节点、pod的CPU、内存、文件系统、网络使用等资源使用情况，而kubelet则通过Metrics Server获取所在节点及容器的上的数据。
kube-api-server的端口是多少？各个pod是如何访问kube-api-server的？
    kube-api-server的端口是8080和6443，前者是http的端口，后者是https的端口，以我本机使用kubeadm安装的k8s为例：
    在命名空间的kube-system命名空间里，有一个名称为kube-api-master的pod，这个pod就是运行着kube-api-server进程，它绑定了master主机的ip地址和6443端口，但是在default命名空间下，存在一个叫kubernetes的服务，该服务对外暴露端口为443，目标端口6443，这个服务的ip地址是clusterip地址池里面的第一个地址，同时这个服务的yaml定义里面并没有指定标签选择器，也就是说这个kubernetes服务所对应的endpoint是手动创建的，该endpoint也是名称叫做kubernetes，该endpoint的yaml定义里面代理到master节点的6443端口，也就是kube-api-server的IP和端口。这样一来，其他pod访问kube-api-server的整个流程就是：pod创建后嵌入了环境变量，pod获取到了kubernetes这个服务的ip和443端口，请求到kubernetes这个服务其实就是转发到了master节点上的6443端口的kube-api-server这个pod里面。
k8s中命名空间的作用是什么？
    amespace是kubernetes系统中的一种非常重要的资源，namespace的主要作用是用来实现多套环境的资源隔离，或者说是多租户的资源隔离。
    k8s通过将集群内部的资源分配到不同的namespace中，可以形成逻辑上的隔离，以方便不同的资源进行隔离使用和管理。不同的命名空间可以存在同名的资源，命名空间为资源提供了一个作用域。
    可以通过k8s的授权机制，将不同的namespace交给不同的租户进行管理，这样就实现了多租户的资源隔离，还可以结合k8s的资源配额机制，限定不同的租户能占用的资源，例如CPU使用量、内存使用量等等来实现租户可用资源的管理。































